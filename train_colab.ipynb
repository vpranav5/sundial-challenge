{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Vacation Planner - LoRA Fine-tuning on Colab GPU\n",
        "\n",
        "This notebook trains a vacation planning agent with LoRA on GPU.\n",
        "\n",
        "**Setup:**\n",
        "1. Runtime â†’ Change runtime type â†’ T4 GPU\n",
        "2. Run all cells\n",
        "3. Download trained weights at the end"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Clone Repository"
      ],
      "metadata": {
        "id": "clone-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone your GitHub repo\n",
        "!git clone https://github.com/vpranav5/sundial-challenge.git\n",
        "%cd sundial-challenge\n",
        "!ls -la"
      ],
      "metadata": {
        "id": "clone-repo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Install Dependencies"
      ],
      "metadata": {
        "id": "install-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -q torch transformers peft bitsandbytes accelerate sentence-transformers tqdm\n",
        "\n",
        "# Verify GPU\n",
        "import torch\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU Name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")"
      ],
      "metadata": {
        "id": "install-deps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Generate Training Data"
      ],
      "metadata": {
        "id": "data-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate synthetic vacation planning conversations\n",
        "from data_gen import VacationDataGenerator\n",
        "\n",
        "generator = VacationDataGenerator()\n",
        "generator.save_dataset(\"vacation_train.json\", num_examples=150)\n",
        "generator.save_dataset(\"vacation_val.json\", num_examples=30)\n",
        "\n",
        "print(\"\\nâœ… Training data generated!\")"
      ],
      "metadata": {
        "id": "gen-data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Train Model with LoRA\n",
        "\n",
        "**Training time:** ~15-20 minutes on T4 GPU"
      ],
      "metadata": {
        "id": "train-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from models import VacationPlannerLLM\n",
        "\n",
        "# Configuration\n",
        "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"  # Open model, no auth needed\n",
        "lora_r = 16  # Higher rank for GPU\n",
        "batch_size = 4  # Larger batch for GPU\n",
        "max_steps = 100  # More steps for better quality\n",
        "output_dir = \"./models/vacation-planner-lora\"\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"VACATION PLANNER - LoRA Fine-tuning (GPU)\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nConfig:\")\n",
        "print(f\"  Model: {model_name}\")\n",
        "print(f\"  LoRA rank: {lora_r}\")\n",
        "print(f\"  Steps: {max_steps}\")\n",
        "print(f\"  Batch size: {batch_size}\")\n",
        "print(f\"  Estimated time: 15-20 minutes\\n\")\n",
        "\n",
        "# Initialize and train\n",
        "llm = VacationPlannerLLM(model_name=model_name, lora_r=lora_r)\n",
        "llm.load_base_model()\n",
        "\n",
        "print(\"\\nðŸš€ Starting training...\\n\")\n",
        "llm.train(\n",
        "    \"vacation_train.json\",\n",
        "    \"vacation_val.json\",\n",
        "    output_dir,\n",
        "    batch_size=batch_size,\n",
        "    max_steps=max_steps\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"âœ… TRAINING COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nModel saved to: {output_dir}\")"
      ],
      "metadata": {
        "id": "train-model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Test the Model"
      ],
      "metadata": {
        "id": "test-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick test\n",
        "test_prompt = \"Present 3 vacation options for Bali with budget hotels and adventure activities\"\n",
        "response = llm.generate(test_prompt, max_length=200)\n",
        "print(\"Test Generation:\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "test-model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Download Trained Weights\n",
        "\n",
        "Download these files to your local machine and place them in `./models/vacation-planner-lora/`"
      ],
      "metadata": {
        "id": "download-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip the model files\n",
        "!zip -r vacation-planner-lora.zip ./models/vacation-planner-lora/\n",
        "\n",
        "# Download link\n",
        "from google.colab import files\n",
        "files.download('vacation-planner-lora.zip')\n",
        "\n",
        "print(\"\\nâœ… Download started! Extract the zip file to ./models/vacation-planner-lora/ on your local machine.\")"
      ],
      "metadata": {
        "id": "download-weights"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Usage Instructions\n",
        "\n",
        "After downloading the weights:\n",
        "\n",
        "```bash\n",
        "# On your local machine\n",
        "cd ~/Desktop/sundial\n",
        "unzip vacation-planner-lora.zip\n",
        "\n",
        "# Run with fine-tuned model in demo mode\n",
        "python main.py --demo --use-finetuned-llm\n",
        "```"
      ],
      "metadata": {
        "id": "usage-header"
      }
    }
  ]
}
